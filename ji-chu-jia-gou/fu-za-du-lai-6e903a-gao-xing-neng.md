# 复杂度来源 : 高性能

软件系统中高性能带来的复杂度主要体现在两方面 , 一方面是单台计算机内部为了高性能带来的复杂度 ; 另一方面是多台计算机集群为了高性能带来的复杂度 .

#### 单机复杂度

计算机内部复杂度最关键的地方就是操作系统 . 操作系统的复杂度直接决定了软件系统的复杂度 .

操作系统和性能相关的就是**进程**和**线程** .

早在没有操作系统时 , 输入一个指令 , 计算然后输出 . 为了解决手工操作带来的低效 , 批处理操作系统应运而生 . **批处理**就是把指令预先写下来 , 到纸带 , 磁带 , 磁盘等 . 然后将这个清单任务交给计算机执行 .

批处理大大提升了处理性能 , 但明显的一个缺点是计算机一次只能执行一个任务 , 如果某个任务需要从I/O设备读取大量的数据 , 在这个过程中 , CPU其实是空闲的 , 而这个空闲时间本来是可以进行其他计算的 .

为了进一步提升性能 , **进程**发明了出来 , 用进程来对应一个任务 , 每个任务都有自己独立的内存空间 , 进程间互互不相关 , 由操作系统来进行调度 . 此时的CPU还没有多核和多线程的概念 , 为了达到**多进程并行**的目的 , 采取了**分时**的方式 , 即把CPU的时间分成很多段 , 每个片段只能执行某个进程中的指令 . 虽然从操作系统和CPU的角度来说还是**串行处理**的 , 但是由于CPU的处理速度很快 , 从用户的角度来看 , 感觉是多进程在并行处理 .

**多进程**虽然要求每个任务都有独立的内存空间 , 进程间互不相关 , 但从用户的角度来看 , 两个任务之间能够在运行过程中就进行通信 , 会让任务设计变得更加灵活高效 . 否则如果两个任务运行过程中不能通信 , 只能是A任务将结果写到存储 , B任务再从存储读取进行处理 , 不仅效率低 , 而且任务设计更加复杂 . 为了解决这个问题 , **进程间通信**的各种方式就被设计了出来 , 包括**管道** , **消息队列** , **信号量** , **共享存储**等 .

多进程让多任务能够并行处理任务 , 但本身还有缺点 , 单个进程内部只能串行处理 , 而实际上很多进程内部的子任务并不要求是严格按照时间顺序来执行的 , 也需要并行处理 . 例如 , 一个餐馆管理进程 , 排位 , 点菜 , 买单 , 服务员调度等子任务必须能够并行处理 , 否则就会出现某个客人买单时间比较长\(比如信用卡刷不出来了\) , 其他客人都不能点菜的情况 . 为了解决这个问题 , 人们又发明了**线程** , **线程是进程内部的子任务** , 但这些子任务都**共享同一份进程数据** . 为了确保数据的正确性 , 又发明了**互斥锁机制** . 有了多线程后 , **操作系统调度的最小单位就变成了线程 , 而进程变成了操作系统分配资源的最小单位 .**

多进程多线程虽然让多任务并行处理的性能大大提升 , 但本质上还是分时系统 , 并不能做到时间上真正的并行 . 解决这个问题的方式显而易见 , 就是**让多个CPU能够同时执行计算任务 , 从而实现真正意义上的多任务并行** . 目前有3种解决方案 :

* SMP（Symmetric Multi-Processor , 对称多处理器结构）
* NUMA（Non-Uniform Memory Access , 非一致存储访问结构）
* MPP（Massive Parallel Processing , 海量并行处理结构）

目前流行的多核处理器就是SMP方案 .

一个高性能的软件系统 , 需要考虑多进程 , 多线程 , 进程间通信 , 多线程并发等技术点 , 而且这些技术并不是最新的就是最好的 , 也不是非此即彼的选择 . 在做架构设计的时候 , 需要花费很大的精力来结合业务进行分析 , 判断 , 选择 , 组合 , 这个过程同样很复杂 .

例如 , Nginx可以用多进程也可以用多线程 , JBoss采用的是多线程 , Redis采用的是单进程 , Memcache采用的是多线程 , 这些系统都实现了高性能 , 但内部实现差异却很大 . 



